{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version 2.1.2\n",
      "cuda available True\n",
      "cudnn True\n",
      "device_name NVIDIA GeForce GTX TITAN X\n",
      "device count 4\n",
      "current dev 0\n",
      "device zero <torch.cuda.device object at 0x7fbcc8634be0>\n"
     ]
    }
   ],
   "source": [
    "# test for cuda and cudnn\n",
    "import torch\n",
    "print(\"version\", torch.__version__)\n",
    "print(\"cuda available\", torch.cuda.is_available())\n",
    "print(\"cudnn\", torch.backends.cudnn.enabled)\n",
    "print(\"device_name\", torch.cuda.get_device_name(0))\n",
    "print(\"device count\", torch.cuda.device_count())\n",
    "print(\"current dev\", torch.cuda.current_device())\n",
    "print(\"device zero\", torch.cuda.device(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Player at (78, 103), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocatari.core import OCAtari\n",
    "import random\n",
    "\n",
    "env = OCAtari(\"MsPacman-v4\", mode=\"vision\", hud=True, render_mode=\"rgb_array\")\n",
    "observation, info = env.reset()\n",
    "env.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Player at (78, 103), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocatari.ram.extract_ram_info import detect_objects_raw, detect_objects_revised, init_objects, get_max_objects\n",
    "\n",
    "objects = init_objects(\"MsPacman\", True)\n",
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## S - train every 1\n",
    "\n",
    "Rank-0: policy_step=421, reward_env_0=220.0\n",
    "Rank-0: policy_step=854, reward_env_0=180.0\n",
    "Rank-0: policy_step=1331, reward_env_0=400.0\n",
    "Rank-0: policy_step=2136, reward_env_0=500.0\n",
    "Rank-0: policy_step=2879, reward_env_0=390.0\n",
    "Rank-0: policy_step=3341, reward_env_0=280.0\n",
    "Rank-0: policy_step=3830, reward_env_0=120.0\n",
    "Rank-0: policy_step=4341, reward_env_0=240.0\n",
    "Rank-0: policy_step=4692, reward_env_0=190.0\n",
    "Rank-0: policy_step=5185, reward_env_0=170.0\n",
    "Rank-0: policy_step=5594, reward_env_0=230.0\n",
    "Rank-0: policy_step=6347, reward_env_0=560.0\n",
    "Rank-0: policy_step=6961, reward_env_0=680.0\n",
    "Rank-0: policy_step=7528, reward_env_0=510.0\n",
    "Rank-0: policy_step=7833, reward_env_0=240.0\n",
    "Rank-0: policy_step=8581, reward_env_0=540.0\n",
    "Rank-0: policy_step=9235, reward_env_0=590.0\n",
    "Rank-0: policy_step=9610, reward_env_0=380.0\n",
    "Rank-0: policy_step=10179, reward_env_0=390.0\n",
    "Rank-0: policy_step=10685, reward_env_0=640.0\n",
    "Rank-0: policy_step=11136, reward_env_0=440.0\n",
    "Rank-0: policy_step=11460, reward_env_0=270.0\n",
    "Rank-0: policy_step=11924, reward_env_0=480.0\n",
    "Rank-0: policy_step=12834, reward_env_0=740.0\n",
    "Rank-0: policy_step=13457, reward_env_0=650.0\n",
    "Rank-0: policy_step=13974, reward_env_0=1030.0\n",
    "Rank-0: policy_step=14669, reward_env_0=730.0\n",
    "Rank-0: policy_step=15442, reward_env_0=1150.0\n",
    "Rank-0: policy_step=16229, reward_env_0=2140.0\n",
    "Rank-0: policy_step=16719, reward_env_0=480.0\n",
    "Rank-0: policy_step=17116, reward_env_0=360.0\n",
    "Rank-0: policy_step=17831, reward_env_0=850.0\n",
    "Rank-0: policy_step=18534, reward_env_0=770.0\n",
    "Rank-0: policy_step=19293, reward_env_0=690.0\n",
    "Rank-0: policy_step=19894, reward_env_0=530.0\n",
    "Rank-0: policy_step=20535, reward_env_0=1480.0\n",
    "Rank-0: policy_step=21004, reward_env_0=350.0\n",
    "Rank-0: policy_step=21618, reward_env_0=1390.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETRIEVE LOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WEB scraping\n",
    "import pandas as pd\n",
    "import requests\n",
    "from csv import reader\n",
    "import os\n",
    "\n",
    "\n",
    "def URLs(fold, trial):\n",
    "    URLs_dict = {\n",
    "    'avg_rew' : f'http://localhost:6006/data/plugin/scalars/scalars?tag=epoch_accuracy&run=fold{fold}%5C{trial}%5Cexecution0%5Ctrain&format=csv',\n",
    "    'val_accuracy' : f'http://localhost:6006/data/plugin/scalars/scalars?tag=epoch_accuracy&run=fold{fold}%5C{trial}%5Cexecution0%5Cvalidation&format=csv',\n",
    "    'val_loss' : f'http://localhost:6006/data/plugin/scalars/scalars?tag=epoch_loss&run=fold{fold}%5C{trial}%5Cexecution0%5Cvalidation&format=csv',\n",
    "    'train_loss' : f'http://localhost:6006/data/plugin/scalars/scalars?tag=epoch_loss&run=fold{fold}%5C{trial}%5Cexecution0%5Ctrain&format=csv'\n",
    "    }\n",
    "    return URLs_dict\n",
    "\n",
    "def tb_data(log_dir, mode, fold, num_trials):\n",
    "    trials = os.listdir(log_dir)\n",
    "    fdf = {}\n",
    "    for i, trial in enumerate(trials[:num_trials]):\n",
    "        r = requests.get(URLs(fold, trial)[mode], allow_redirects=True)\n",
    "        data = r.text\n",
    "        data_csv = reader(data.splitlines())\n",
    "        data_csv = list(data_csv)\n",
    "        df = pd.DataFrame(data_csv)\n",
    "        headers = df.iloc[0]\n",
    "        df  = pd.DataFrame(df.values[1:], columns=headers)\n",
    "        if i == 0:\n",
    "            fdf['Step'] = df['Step']  \n",
    "        fdf[f'trial {trial}'] = df['Value']\n",
    "    fdf = pd.DataFrame(fdf)\n",
    "    return fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tensorboard Scalar Plotting #1\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "TAG_NAME = \"classification_loss\"\n",
    "\n",
    "writer_train = tf.summary.create_file_writer(\"train\")\n",
    "\n",
    "for epoch in range(200):\n",
    "    data = np.math.exp(-(epoch/30)) + 0.1*np.random.random()\n",
    "    with writer_train.as_default():\n",
    "        tf.summary.scalar(name=TAG_NAME, data=data, step=epoch)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TAG_NAME = \"classification_loss\"\n",
    "tf_event_file = \"train/events.out.tfevents.1618103384.eafddbceac44.283.2075165.v2\"\n",
    "\n",
    "value_list = []\n",
    "for e in tf.compat.v1.train.summary_iterator(tf_event_file):\n",
    "    for v in e.summary.value:\n",
    "        if v.tag == TAG_NAME:\n",
    "            value = tf.make_ndarray(v.tensor)\n",
    "            value_list.append(value)\n",
    "\n",
    "plt.plot(value_list)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tensorboard Scalar Plotting #2\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_scalar_run_tensorboard(tag, filepath):\n",
    "    values,steps = [],[]\n",
    "    for e in tf.compat.v1.train.summary_iterator(filepath):\n",
    "        if len(e.summary.value)>0: #Skip first empty element\n",
    "            if e.summary.value[0].tag==tag:\n",
    "                tensor = (e.summary.value[0].tensor)\n",
    "                value,step = (tf.io.decode_raw(tensor.tensor_content,tf.float32)[0].numpy(),e.step)\n",
    "                values.append(value)\n",
    "                steps.append(step)\n",
    "    return values,steps\n",
    "\n",
    "val,st = get_scalar_run_tensorboard(\"epoch_loss\",\n",
    "                               \"./logs/your_log/your_run/train/your_file.v2\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(st,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
