{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version 2.1.2\n",
      "cuda available True\n",
      "cudnn True\n",
      "device_name NVIDIA GeForce GTX TITAN X\n",
      "device count 4\n",
      "current dev 0\n",
      "device zero <torch.cuda.device object at 0x7fbcc8634be0>\n"
     ]
    }
   ],
   "source": [
    "# test for cuda and cudnn\n",
    "import torch\n",
    "print(\"version\", torch.__version__)\n",
    "print(\"cuda available\", torch.cuda.is_available())\n",
    "print(\"cudnn\", torch.backends.cudnn.enabled)\n",
    "print(\"device_name\", torch.cuda.get_device_name(0))\n",
    "print(\"device count\", torch.cuda.device_count())\n",
    "print(\"current dev\", torch.cuda.current_device())\n",
    "print(\"device zero\", torch.cuda.device(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Player at (78, 103), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocatari.core import OCAtari\n",
    "import random\n",
    "\n",
    "env = OCAtari(\"MsPacman-v4\", mode=\"vision\", hud=True, render_mode=\"rgb_array\")\n",
    "observation, info = env.reset()\n",
    "env.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Player at (78, 103), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " Ghost at (79, 57), (9, 10),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocatari.ram.extract_ram_info import detect_objects_raw, detect_objects_revised, init_objects, get_max_objects\n",
    "\n",
    "objects = init_objects(\"MsPacman\", True)\n",
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## S - train every 1\n",
    "\n",
    "Rank-0: policy_step=421, reward_env_0=220.0\n",
    "Rank-0: policy_step=854, reward_env_0=180.0\n",
    "Rank-0: policy_step=1331, reward_env_0=400.0\n",
    "Rank-0: policy_step=2136, reward_env_0=500.0\n",
    "Rank-0: policy_step=2879, reward_env_0=390.0\n",
    "Rank-0: policy_step=3341, reward_env_0=280.0\n",
    "Rank-0: policy_step=3830, reward_env_0=120.0\n",
    "Rank-0: policy_step=4341, reward_env_0=240.0\n",
    "Rank-0: policy_step=4692, reward_env_0=190.0\n",
    "Rank-0: policy_step=5185, reward_env_0=170.0\n",
    "Rank-0: policy_step=5594, reward_env_0=230.0\n",
    "Rank-0: policy_step=6347, reward_env_0=560.0\n",
    "Rank-0: policy_step=6961, reward_env_0=680.0\n",
    "Rank-0: policy_step=7528, reward_env_0=510.0\n",
    "Rank-0: policy_step=7833, reward_env_0=240.0\n",
    "Rank-0: policy_step=8581, reward_env_0=540.0\n",
    "Rank-0: policy_step=9235, reward_env_0=590.0\n",
    "Rank-0: policy_step=9610, reward_env_0=380.0\n",
    "Rank-0: policy_step=10179, reward_env_0=390.0\n",
    "Rank-0: policy_step=10685, reward_env_0=640.0\n",
    "Rank-0: policy_step=11136, reward_env_0=440.0\n",
    "Rank-0: policy_step=11460, reward_env_0=270.0\n",
    "Rank-0: policy_step=11924, reward_env_0=480.0\n",
    "Rank-0: policy_step=12834, reward_env_0=740.0\n",
    "Rank-0: policy_step=13457, reward_env_0=650.0\n",
    "Rank-0: policy_step=13974, reward_env_0=1030.0\n",
    "Rank-0: policy_step=14669, reward_env_0=730.0\n",
    "Rank-0: policy_step=15442, reward_env_0=1150.0\n",
    "Rank-0: policy_step=16229, reward_env_0=2140.0\n",
    "Rank-0: policy_step=16719, reward_env_0=480.0\n",
    "Rank-0: policy_step=17116, reward_env_0=360.0\n",
    "Rank-0: policy_step=17831, reward_env_0=850.0\n",
    "Rank-0: policy_step=18534, reward_env_0=770.0\n",
    "Rank-0: policy_step=19293, reward_env_0=690.0\n",
    "Rank-0: policy_step=19894, reward_env_0=530.0\n",
    "Rank-0: policy_step=20535, reward_env_0=1480.0\n",
    "Rank-0: policy_step=21004, reward_env_0=350.0\n",
    "Rank-0: policy_step=21618, reward_env_0=1390.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
